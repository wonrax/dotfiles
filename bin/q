#!/usr/bin/env nu
# q - Quick LLM queries with LLM CLIs
# Inspired by https://entropicthoughts.com/q
# Created using Deepseek R1 with supervision.

# Predefined system prompts
const system_prompts = {
    brief: "Answer in as few words as possible. Use a brief style with short replies."
    detailed: "Provide a thorough explanation with examples and technical details."
    commit: "Generate a concise commit message based on the jj diff. Sample the jj log for conventional format used in the current project. If there isn't any, fallback to conventional commit message. Then use that message to jj describe automatically without asking for user confirmation because the user can then redescribe it later if needed.

    Rules:
    - **IMPORTANT:** Try to limit the first line message length of 72 characters unless necessary.
    - Only let the command output to stdout, DO NOT redirect it to any file.

    For acquiring the diff, use `jj diff --no-pager --config ui.diff.tool='["git", "--no-pager", "diff", "--no-color", "-U32", "$left", "$right"]'` to get the machine readable diff.

    For sampling the commit message, use `jj log -n20 -r ::@ --color=never -T builtin_log_oneline --no-pager`.

    In the end, do not provide any additional text or explanation, since the UI already shows which command you have run.
    "
}

# Get available system prompt names
def get-prompt-names [] {
    $system_prompts | columns
}

# Main function
export def main [
    ...prompt: string  # Prompt as last arguments without quotes
    --recipe (-r): string = "brief"  # Predefined prompt name
    --context (-c): string = ""  # Predefined context string
] {
    # Validate system prompt name
    let valid_prompts = (get-prompt-names)
    if $recipe not-in $valid_prompts {
        error make {
            msg: $"Invalid system prompt '($recipe)'",
            label: {
                text: $"Valid options: ($valid_prompts | str join ', ')"
                span: (metadata $recipe).span
            }
        }
    }

    # Capture piped input if any
    let piped_input = $in

    # Combine all prompt arguments into a single string
    let user_prompt = ($prompt | str join " ")

    # Build the full prompt
    let final_system_prompts = $"
        You are a helpful AI assistant. Your task is to assist the user with
        their queries based on the provided system prompt.

        This chat is oneshot, meaning the user won't be able to ask follow-up
        questions, and you should not ask for any clarifications or additional
        information. Provide a complete answer based on the provided context
        and perform any necessary actions without further interaction.

        ($system_prompts | get $recipe)

        (if $context != "" { $"CONTEXT:\n($context)\n\n" })
        (if not ($piped_input | is-empty) { $"INPUT:\n($piped_input)\n\n" })
    " | str trim

    if $final_system_prompts == "" {
        error make {msg: "Error: No input provided"}
    }

    opencode run --model github-copilot/claude-sonnet-4.5 $final_system_prompts $user_prompt
}
